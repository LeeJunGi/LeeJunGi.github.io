---
title: 9. Prioritized Experience Replay 
author: Jungi Lee
date: 2021-04-25 18:00:00 +0900
categories: [Reinforcement Learning, Single-Agent]
tags: [RL, Single-Agent]
math: true
mermaid: true
---
# 목차 
1. [Problem definition](#problem-definition)  
1. [Priority](#priority)  
1. [Importance Sampling](#importance-sampling)  
1. [Importance Sampling Weight](#importance-sampling-weight)  
1. [Algorithm](#algorithm)  
1. [Reference](#reference)  

# Problem definition

기존 Experience replay buffer는 uniform하게 선택하여 우선 순위가 없다. 우선 순위를 매기면 state correlation이 높아질 수 있다는 문제가 있다. 그러므로 우선 순위의 장점과 random sample의 장점을 잘 섞어보는 것이 목적이다.

# Priority

Replay buffer가 커질수록 중요한 sample을 뽑을 확률이 감소한다.

그러므로 TD error를 우선 순위 지표로 사용해서 확률을 높이자.

$$P(i) = \frac{P^a_i}{\sum_k P^a_k}$$  

a가 0 이면 uniform하게 선택하고 클수록 TD error에 민감하게 반응한다.  
$$P_i$$를 선정하는 방식은 두가지로 TD error를 그대로 사용하는 방법과 TD error의 rank를 사용하는 방법이다. 


$$P_i = \vert \delta_i \vert + \epsilon$$  

where $$\delta$$ is TD error and $$\epsilon$$ is small value for preventing $$P_i$$ become 0  

$$P_i = \frac{1}{\text{rank}(i)}$$

example)  
TD_error=[12, 2, 0]  
rank = [1, 2, 3]  
$$P_i = [1, \frac{1}{2}, \frac{1}{3}]$$

# Importance Sampling

Importance sampling은 원래 확률이 $$P_i$$지만 우리가 가지고 있는 확률 분포가 $$Q_i$$일 때 $$Q_i$$를 이용하여 $$P_i$$를 추정하는 방법이다.

$$E[X] = \underset{i=1}{\overset{N}{\sum}} x_i p_i = \underset{i=1}{\overset{N}{\sum}} x_i \frac{p_i}{q_i}q_i$$

# Importance Sampling Weight

논문에서는 원래 확률 분포 $$P_i$$는 uniform distribution이라고 하고 $$Q_i$$는 TD_error로 설정하였다. 이때 Importance Sampling Weight는 아래와 같다.

$$\frac{\frac{1}{N}}{P_i} = \frac{1}{NP_i}$$

$$\text{Importance Sampling Weight} = (\frac{1}{NP_i})^{\beta}$$

$$\beta$$가 1 일 경우 uniform의 경향을 최대한 고려하는 것이고 0일 경우 완전히 무시하는 것을 의미한다.

# Algorithm

![algorithm][algorithm]
_PER algorithm_

# Reference
1. [혁펜하임 유투브][혁펜하임 유투브]  
1. [Schaul, Tom, et al. "Prioritized experience replay." arXiv preprint arXiv:1511.05952 (2015).][PER]

[혁펜하임 유투브]: https://www.youtube.com/watch?v=cvctS4xWSaU&list=PL_iJu012NOxehE8fdF9me4TLfbdv3ZW8g  
[PER]: https://arxiv.org/pdf/1511.05952.pdf

[algorithm]: /assets/img/Single-agent/PER/algorithm.png

