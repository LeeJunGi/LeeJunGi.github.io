<!DOCTYPE html><html lang="en-US" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="pv-cache-enabled" content="false"><meta name="generator" content="Jekyll v4.2.0" /><meta property="og:title" content="(Gong 2019 ICCV) Memorizing Normality to Detect Anomaly; Memory-augmented Deep Autoencoder for Unsupervised Anomaly Detection" /><meta name="author" content="Jungi Lee" /><meta property="og:locale" content="en_US" /><meta name="description" content="목차 Introduction Memory-augmented Autoencoder Memory module Memory-based Representation Attention for Memory Addressing Hard Shrinkage for Sparse Addressing Training Experiment Reference" /><meta property="og:description" content="목차 Introduction Memory-augmented Autoencoder Memory module Memory-based Representation Attention for Memory Addressing Hard Shrinkage for Sparse Addressing Training Experiment Reference" /><link rel="canonical" href="https://leejungi.github.io/posts/MemAE/" /><meta property="og:url" content="https://leejungi.github.io/posts/MemAE/" /><meta property="og:site_name" content="JG_blog" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-02-10T00:00:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="(Gong 2019 ICCV) Memorizing Normality to Detect Anomaly; Memory-augmented Deep Autoencoder for Unsupervised Anomaly Detection" /><meta name="twitter:site" content="@twitter_username" /><meta name="twitter:creator" content="@Jungi Lee" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"author":{"@type":"Person","name":"Jungi Lee"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://leejungi.github.io/posts/MemAE/"},"description":"목차 Introduction Memory-augmented Autoencoder Memory module Memory-based Representation Attention for Memory Addressing Hard Shrinkage for Sparse Addressing Training Experiment Reference","url":"https://leejungi.github.io/posts/MemAE/","@type":"BlogPosting","headline":"(Gong 2019 ICCV) Memorizing Normality to Detect Anomaly; Memory-augmented Deep Autoencoder for Unsupervised Anomaly Detection","dateModified":"2022-02-10T00:00:00+09:00","datePublished":"2022-02-10T00:00:00+09:00","@context":"https://schema.org"}</script><title>(Gong 2019 ICCV) Memorizing Normality to Detect Anomaly; Memory-augmented Deep Autoencoder for Unsupervised Anomaly Detection | JG_blog</title><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="cdn.jsdelivr.net"><link rel="dns-prefetch" href="cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script defer src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id="></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', ''); }); </script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/assets/img/carrot.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">JG_blog</a></div><div class="site-subtitle font-italic">RL researcher and developer</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT ME</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/leejungi" aria-label="github" class="order-3" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" class="order-4" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['ganbbang12','naver.com'].join('@')" aria-label="email" class="order-5" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" class="order-6" > <i class="fas fa-rss"></i> </a> <span class="icon-border order-2"></span> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>(Gong 2019 ICCV) Memorizing Normality to Detect Anomaly; Memory-augmented Deep Autoencoder for Unsupervised Anomaly Detection</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>(Gong 2019 ICCV) Memorizing Normality to Detect Anomaly; Memory-augmented Deep Autoencoder for Unsupervised Anomaly Detection</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Thu, Feb 10, 2022, 12:00 AM +0900" > Feb 10 <i class="unloaded">2022-02-10T00:00:00+09:00</i> </span> by <span class="author"> Jungi Lee </span></div><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1331 words">7 min</span></div></div><div class="post-content"><h1 id="목차">목차</h1><ol><li><a href="#introduction">Introduction</a><li><a href="#memory-augmented-autoencoder">Memory-augmented Autoencoder</a><li><a href="#memory-module">Memory module</a><ul><li><a href="#memory-based-representation">Memory-based Representation</a><li><a href="#attention-for-memory-addressing">Attention for Memory Addressing</a><li><a href="#hard-shrinkage-for-sparse-addressing">Hard Shrinkage for Sparse Addressing</a></ul><li><a href="#training">Training</a><li><a href="#experiment">Experiment</a><li><a href="#reference">Reference</a></ol><h1 id="introduction">Introduction</h1><p>보통의 Anomaly Detection 논문들은 Auto Encoder를 이용하여 Reconstruction Error를 이용한 방법을 사용한다. Anomaly Detection의 가정으로 가지고 있는 데이터가 전부 정상이거나 일부분만 비정상이다. 또한 이 비정상의 데이터가 어떤 것인지 모른다는 가정이 있다. 일부 논문들에서는 비정상(abnomaly)의 데이터를 가지고 있다는 전제 조건하에 supervised 혹은 semi-supervised 방법을 제시하지만 기본적으로 unsupervised인 Auto Encoder를 이용한 방법이 여전히 많이 사용되고 있긴하다. 데이터의 분포의 가정을 이용하여 학습 시 대부분 정상의 패턴을 학습하게 된다는 것을 이용한다. 이 논문에서는 이 부분에서 발생하는 문제점을 정의하고 있다.</p><p>Autoencoder를 이용한 논문은 정상 데이터를 대부분 학습하여 비정상 데이터를 입력하여 정상으로 재구성된다고 얘기한다. 그래서 입력과 출력의 차이를 이용하여 비정상 데이터를 구분한다. 하지만 auto encoder는 너무 잘 일반화가 된다면 비정상이 입려되어도 비정상 데이터를 잘 재구성하여 출력이 정상이 아닌 입력된 비정상에 가까워 질 수 있다고 얘기한다. 아래 그림은 그 예시로 MNIST 데이터에서 5를 정상으로 하여 학습을 진행하였지만 9를 입력하였을 때 5가 아닌 비정상 입력인 9에 가깝게 재구성되는 것을 확인할 수 있다.</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/DNN/MemAE/motivation.png" alt="motivation" /> <em>Motivation</em></p><p>이 문제를 해결하기 위해서 논문에서는 latent vector를 그대로 사용하는 것이 아닌 메모리를 두어 메모리에 있는 latent vector와 현재 latent vector를 비교하여 가장 비슷한 latent vector 메모리에서 꺼내와서 사용하자는 것이다. 그렇게된다면 latent vector는 정상의 정보를 담고 있을 것이므로 재구성되는 이미지 또한 정상일 것이다라고 주장한다.</p><h1 id="memory-augmented-autoencoder">Memory-augmented Autoencoder</h1><p>아래 그림은 Memory-agumented Autoencoder(MemAE)의 구조이다. 일반적인 Autoencoder와 비슷하지만 latent vector를 그대로 decoder에 넘기는 것이 아닌 memory module을 통과하여 생성된 latent vector를 사용하는 것이 다르다.</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/DNN/MemAE/archi.png" alt="archi" /> <em>Memory-augmented Autoencoder</em></p><h1 id="memory-module">Memory module</h1><h2 id="memory-based-representation">Memory-based Representation</h2><p>몇가지 notation을 정의한다.</p><ul><li>M: memory \(M \in \mathbb{R}^{N\times C}\)<li>N: memory size<li>C: latent vector size(representation dimension)<li>z, \(\mathbb{Z}\): latent vector from encoder \(\mathbb{Z}= \mathbb{R}^C\)<li>\(\hat{z}\): latent vector from memory module<li>w: soft addressing vector \(\text{w} \in \mathbb{R}^{1 \times N}\)</ul><p>해당 논문에서 \(\hat{z}\)의 공식은 아래와 같다.</p>\[\hat{z} = \text{w}M = \sum^N_{i=1} w_i m_i\]<h2 id="attention-for-memory-addressing">Attention for Memory Addressing</h2><p>w는 attention score라고 할 수 있다. 식은 아래와 같다.</p>\[w_i = \frac{\text{exp}(d(z,m_i))}{\sum^N_{j=1}\text{exp}(d(z,m_j))}\]<p>여기서 $d(\cdot,\cdot)$$은 유사도를 나타내고 이 논문에서는 cosine similarity를 사용한다.</p>\[d(z,m_i) = \frac{zm_i^\text{T}}{\vert \vert z \vert \vert \vert \vert m_i \vert \vert}\]<p>메모리 사이즈가 제한적이기 때문에 다음 섹션에서 소개될 sparse addressing technique을 사용한다.</p><h2 id="hard-shrinkage-for-sparse-addressing">Hard Shrinkage for Sparse Addressing</h2><p>제한된 메모리에 있는 정상 패턴은 비정상 데이터에 대해 재구성 에러를 높게만드는 데 도움이 된다고 한다. 그렇지만 여전히 몇몇 비정상 데이터는 메모리에 있는 정보를 조합하여 재구성이 잘될 수 있다. 그래서 복잡하게 정보를 재조합하여 사용하지 못하도록 w에 hard shrinkage operation을 추가하여 w를 sparse하게 만든다.</p>\[\hat{w}_i = h(w_i; \lambda) = \begin{cases} w_i, &amp;\text{if}\: w_i &gt;\lambda \\ 0, &amp;\text{otherwise} \end{cases}\]<p>w는 non-negative여야하기 때문에 continuous ReLU activation function을 사용하였다.</p>\[\hat{w_i} = \frac{\text{max}(w_i - \lambda, 0) \cdot w_i}{\vert w_i - \lambda \vert + \epsilon}\]<p>Shrinkage 이후 \(\hat{w}\)를 renormalize한다.</p>\[\hat{w_i} = \hat{w_i} / || \hat{w} ||_1\]<p>이렇게 만든 Shrinkage \(\hat{w}\)를 이용하여 새롭게 latent vector를 만든다.</p>\[\hat{z} = \hat{w}M\]<h1 id="training">Training</h1><p>기본적으로 AutoEncoder와 동일하게 reconstruction error를 loss로 사용한다.</p>\[R(x^t, \hat{x}^t) = || x^t - \hat{x}^t ||^2_2\]<p>또한 sparse한 w를 위해서 entropy loss를 사용한다.(entropy loss를 최소화하면 오히려 uniform distribution에서 멀어질 텐데 왜 이렇게 한지 모르겠다.)</p>\[E(\hat{w}^t) = \sum^T_{i=1} - \hat{w_i} \cdot \operatorname{log}(\hat{w_i})\]<p>최종 loss는 아래와 같다.</p>\[L(\theta_e, \theta_d, M) = \frac{1}{T} \sum^T_{t=1} (R(x^t, \hat{x}^t) + \alpha E(\hat{w}^t))\]<h1 id="experiment">Experiment</h1><p>MNIST와 Cifar-10에서 결과를 확인하면 가장 좋은 결과를 보여주는 것을 확인할 수 있다.</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/DNN/MemAE/exp1.png" alt="exp1" /> <em>Experiment 1</em></p><p>다른 데이터셋에서 비교를 하면 Sparsity가 의미가 있는 것을 확인할 수 있다.</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/DNN/MemAE/exp2.png" alt="exp2" /> <em>Experiment 2</em></p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/DNN/MemAE/exp3.png" alt="exp3" /> <em>Experiment 3</em></p><p>Ablation study를 확인하면 각각의 제안 방법들의 영향을 알 수 있다. nonSparsity를 사용하는 것보다 shrinkage나 entropy loss를 사용하는 것은 각각 더 좋은 결과를 보여주고 둘이 같이 사용하는 것이 가장 좋은 결과를 보여주는 것을 확인할 수 있다.</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/DNN/MemAE/exp4.png" alt="exp4" /> <em>Experiment 4</em></p><h1 id="reference">Reference</h1><ol><li><a href="https://arxiv.org/pdf/1904.02639.pdf">Gong, Dong, et al. “Memorizing normality to detect anomaly: Memory-augmented deep autoencoder for unsupervised anomaly detection.” Proceedings of the IEEE/CVF International Conference on Computer Vision. 2019.</a></ol></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/deep-learning/'>Deep learning</a>, <a href='/categories/anomaly-detection/'>Anomaly Detection</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/deep-learning/" class="post-tag no-text-decoration" >Deep learning</a> <a href="/tags/anomaly-detection/" class="post-tag no-text-decoration" >Anomaly Detection</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=(Gong 2019 ICCV) Memorizing Normality to Detect Anomaly; Memory-augmented Deep Autoencoder for Unsupervised Anomaly Detection - JG_blog&url=https://leejungi.github.io/posts/MemAE/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=(Gong 2019 ICCV) Memorizing Normality to Detect Anomaly; Memory-augmented Deep Autoencoder for Unsupervised Anomaly Detection - JG_blog&u=https://leejungi.github.io/posts/MemAE/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=(Gong 2019 ICCV) Memorizing Normality to Detect Anomaly; Memory-augmented Deep Autoencoder for Unsupervised Anomaly Detection - JG_blog&url=https://leejungi.github.io/posts/MemAE/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/DAGMM/">(Zong 2018 ICLR) Deep Autoencoding Gaussian Mixture Model For Unsupervised Anomaly Detection</a><li><a href="/posts/HIRO/">(Ofir 2018 Nips) Data-Efficient Hierarchical Reinforcement Learning</a><li><a href="/posts/FUN/">(Vezhnevets 2017 ICML) Feudal networks for hierarchical reinforcement learning</a><li><a href="/posts/ASAC/">(Haarnoja 2019 arxiv) Soft Actor-Critic Algorithms and Applications</a><li><a href="/posts/SAC/">(Haarnoja 2018 ICML) Soft Actor-Critic; Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/rl/">RL</a> <a class="post-tag" href="/tags/single-agent/">Single-Agent</a> <a class="post-tag" href="/tags/deep-learning/">Deep learning</a> <a class="post-tag" href="/tags/multi-agent/">Multi-Agent</a> <a class="post-tag" href="/tags/hierarchial-rl/">Hierarchial RL</a> <a class="post-tag" href="/tags/anomaly-detection/">Anomaly Detection</a> <a class="post-tag" href="/tags/distributed-rl/">Distributed RL</a> <a class="post-tag" href="/tags/memo/">memo</a> <a class="post-tag" href="/tags/meta-rl/">Meta-RL</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/DAGMM/"><div class="card-body"> <span class="timeago small" > Sep 10, 2021 <i class="unloaded">2021-09-10T00:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>(Zong 2018 ICLR) Deep Autoencoding Gaussian Mixture Model For Unsupervised Anomaly Detection</h3><div class="text-muted small"><p> 목차 Introduction Deep Autoencoding Gaussian Mixture Model Experiment Reference Introduction anomaly detection은 high dimension data를 이용하여 low dimension으로 reduction을 하고 거기서 의미 있는 정보를 추출해야한...</p></div></div></a></div><div class="card"> <a href="/posts/CapsNet/"><div class="card-body"> <span class="timeago small" > Aug 17, 2021 <i class="unloaded">2021-08-17T03:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>(Hinton 2017 Nips) Dynamic Routing Between Capsules</h3><div class="text-muted small"><p> 목차 Introduction How the vector inputs and outputs of a capsule are computed Margin loss for digit existence CapsNet architecture Comments Reference Introduction 이 논문은 일반적인 CNN의 문제점을...</p></div></div></a></div><div class="card"> <a href="/posts/DRAW/"><div class="card-body"> <span class="timeago small" > Jun 4, 2021 <i class="unloaded">2021-06-04T00:09:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>(Gregor 2015 ICML) DRAW; A Recurrent Neural Network For Image Generation</h3><div class="text-muted small"><p> 목차 Introduction DRAW Architecture Read and Write operations Reference Introduction 이 논문은 generative model 논문으로 VAE와 비슷한 느낌이다. 하지만 VAE와 다르게 RNN 구조가 추가된다. 왜 RNN 구조가 추가 되었나? 사람들이 그림을 그릴 때에서...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/siamese/" class="btn btn-outline-primary" prompt="Older"><p>(Koch 2015 ICML) Siamese Neural Networks for One-shot Image Recognition</p></a> <span class="btn btn-outline-primary disabled" prompt="Newer"><p>-</p></span></div></div></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script> <script type="text/javascript"> const imgs = document.querySelectorAll('.post-content img'); const observer = lozad(imgs); observer.observe(); </script><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2022 <a href="https://twitter.com/username">Jungi Lee</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/rl/">RL</a> <a class="post-tag" href="/tags/single-agent/">Single Agent</a> <a class="post-tag" href="/tags/deep-learning/">Deep learning</a> <a class="post-tag" href="/tags/multi-agent/">Multi Agent</a> <a class="post-tag" href="/tags/hierarchial-rl/">Hierarchial RL</a> <a class="post-tag" href="/tags/anomaly-detection/">Anomaly Detection</a> <a class="post-tag" href="/tags/distributed-rl/">Distributed RL</a> <a class="post-tag" href="/tags/memo/">memo</a> <a class="post-tag" href="/tags/meta-rl/">Meta RL</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><script src="https://cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js"></script> <script> $(function() { let initTheme = "default"; if ($("html[mode=dark]").length > 0 || ($("html[mode]").length == 0 && window.matchMedia("(prefers-color-scheme: dark)").matches ) ) { initTheme = "dark"; } let mermaidConf = { theme: initTheme /* <default|dark|forest|neutral> */ }; /* Markdown converts to HTML */ $("pre").has("code.language-mermaid").each(function() { let svgCode = $(this).children().html(); $(this).addClass("unloaded"); $(this).after(`<div class=\"mermaid\">${svgCode}</div>`); }); mermaid.initialize(mermaidConf); }); </script><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://leejungi.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script>
