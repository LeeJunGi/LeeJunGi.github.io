<feed xmlns="http://www.w3.org/2005/Atom"> <id>https://leejungi.github.io/</id><title>JG_blog</title><subtitle>A minimal, portfolio, sidebar, bootstrap Jekyll theme with responsive web design and focuses on text presentation.</subtitle> <updated>2022-02-11T00:36:52+09:00</updated> <author> <name>Jungi Lee</name> <uri>https://leejungi.github.io/</uri> </author><link rel="self" type="application/atom+xml" href="https://leejungi.github.io/feed.xml"/><link rel="alternate" type="text/html" hreflang="en-US" href="https://leejungi.github.io/"/> <generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator> <rights> © 2022 Jungi Lee </rights> <icon>/assets/img/favicons/favicon.ico</icon> <logo>/assets/img/favicons/favicon-96x96.png</logo> <entry><title>(Gong 2019 ICCV) Memorizing Normality to Detect Anomaly; Memory-augmented Deep Autoencoder for Unsupervised Anomaly Detection</title><link href="https://leejungi.github.io/posts/MemAE/" rel="alternate" type="text/html" title="(Gong 2019 ICCV) Memorizing Normality to Detect Anomaly; Memory-augmented Deep Autoencoder for Unsupervised Anomaly Detection" /><published>2022-02-10T00:00:00+09:00</published> <updated>2022-02-10T00:00:00+09:00</updated> <id>https://leejungi.github.io/posts/MemAE/</id> <content src="https://leejungi.github.io/posts/MemAE/" /> <author> <name>Jungi Lee</name> </author> <category term="Deep learning" /> <category term="Anomaly Detection" /> <summary> 목차 Introduction Memory-augmented Autoencoder Memory module Memory-based Representation Attention for Memory Addressing Hard Shrinkage for Sparse Addressing Training Experiment Reference Introduction 보통의 Anomaly Detection 논문들은 Auto Encoder를 이용하여 Reconstruction Error를 이용한 방법을 사용한다. Anomaly Detection의 가정으로 가지고 있는 데이터가 전부 정상이거나 일부분만 비정상이다. 또한 이 비정상의 데이... </summary> </entry> <entry><title>(Koch 2015 ICML) Siamese Neural Networks for One-shot Image Recognition</title><link href="https://leejungi.github.io/posts/siamese/" rel="alternate" type="text/html" title="(Koch 2015 ICML) Siamese Neural Networks for One-shot Image Recognition" /><published>2022-02-03T00:00:00+09:00</published> <updated>2022-02-03T00:00:00+09:00</updated> <id>https://leejungi.github.io/posts/siamese/</id> <content src="https://leejungi.github.io/posts/siamese/" /> <author> <name>Jungi Lee</name> </author> <category term="Deep learning" /> <summary> 목차 Introduction Model Reference Introduction Few-shot learning과 constractive learning을 섞어놓은 듯한 논문이다. 내 관점에서는 Few-shot learning 느낌보다는 constractive learning에 좀 더 맞지 않나라고 보인다. 이 논문은 사전에 준비해둔 데이터와 들어오는 데이터를 비교하여 같음 다름을 이용하여 분류하는 방법이다. 구조와 loss function 등 매우 간단하고 아이디어도 매우 간단하다. Model Siamese의 모델은 아래 그림과 같다. 간단한 CNN구조로 되어 있지만 다른 점은 input을 하나만 사용하는 것이 아닌 이미 가지고 있는 데이터를 함께 사용하는 것이다. Siames... </summary> </entry> <entry><title>(Lasse 2018 ICML) Impala; Scalable distributed deep-rl with importance weighted actor-learner architectures</title><link href="https://leejungi.github.io/posts/IMPALA/" rel="alternate" type="text/html" title="(Lasse 2018 ICML) Impala; Scalable distributed deep-rl with importance weighted actor-learner architectures" /><published>2021-09-20T01:00:00+09:00</published> <updated>2021-09-20T01:00:00+09:00</updated> <id>https://leejungi.github.io/posts/IMPALA/</id> <content src="https://leejungi.github.io/posts/IMPALA/" /> <author> <name>Jungi Lee</name> </author> <category term="Reinforcement Learning" /> <category term="Distributed RL" /> <summary> 목차 Introduction IMPALA V-trace Reference Introduction 강화학습에는 빠른 학습을 위해서 A3C와 같은 off-policy based distributed learning 방식을 사용한다. A3C는 worker들 간의 gradient을 공유하여 central parameter server를 update하는 방식이다. IMPALA는 experience의 trajectory를 공유를 하여 centralised learner를 학습시킨다. IMPALA 기존 learner policy의 update를 여러 개의 actor를 통해서 학습한다면 policy-lag이라는 actor와 learner 사이의 차이가 발생한다. 이 논문에서는 V-trace라... </summary> </entry> <entry><title>(Zong 2018 ICLR) Deep Autoencoding Gaussian Mixture Model For Unsupervised Anomaly Detection</title><link href="https://leejungi.github.io/posts/DAGMM/" rel="alternate" type="text/html" title="(Zong 2018 ICLR) Deep Autoencoding Gaussian Mixture Model For Unsupervised Anomaly Detection" /><published>2021-09-10T00:00:00+09:00</published> <updated>2022-02-11T00:32:11+09:00</updated> <id>https://leejungi.github.io/posts/DAGMM/</id> <content src="https://leejungi.github.io/posts/DAGMM/" /> <author> <name>Jungi Lee</name> </author> <category term="Deep learning" /> <category term="Anomaly Detection" /> <summary> 목차 Introduction Deep Autoencoding Gaussian Mixture Model Experiment Reference Introduction anomaly detection은 high dimension data를 이용하여 low dimension으로 reduction을 하고 거기서 의미 있는 정보를 추출해야한다. 하지만 이는 suboptimal로 수렴할 수 있으며 이 문제를 해결하기 위해서 autoencoder를 이용하여 low dimension representation과 reconstruction error를 생성한다. 이러한 정보를 이용하여 guassian mixture model을 이용하여 분류를 한다. 이때 Expectation-Maximization... </summary> </entry> <entry><title>(Hinton 2017 Nips) Dynamic Routing Between Capsules</title><link href="https://leejungi.github.io/posts/CapsNet/" rel="alternate" type="text/html" title="(Hinton 2017 Nips) Dynamic Routing Between Capsules" /><published>2021-08-17T03:00:00+09:00</published> <updated>2021-08-17T03:00:00+09:00</updated> <id>https://leejungi.github.io/posts/CapsNet/</id> <content src="https://leejungi.github.io/posts/CapsNet/" /> <author> <name>Jungi Lee</name> </author> <category term="Deep learning" /> <summary> 목차 Introduction How the vector inputs and outputs of a capsule are computed Margin loss for digit existence CapsNet architecture Comments Reference Introduction 이 논문은 일반적인 CNN의 문제점을 해결하기 위해 새로운 네트워크 구조인 Capsule Network를 제안한다. CNN은 simple feature부터 complex feature까지 점차적으로 바뀐다. 그리고 convolution연산을 하기 때문에(weighted sum) 각 feature간의 위치 관계를 고려하지 않는다. CNN에서는 max pooling을 통하여 해결하고자 하였지만 ... </summary> </entry> </feed>
